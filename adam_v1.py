# -*- coding: utf-8 -*-
"""Adam_v1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fkVDw67Xtsg656iOTPBJXl69h21LWls3

# **IMPORTOWANIE BIBLIOTEK**
"""

import numpy as np
import matplotlib.pyplot as plt
import math
from numpy import arange
from numpy import meshgrid
import sympy as smp
import scipy
from scipy.misc import derivative
import datetime
from statistics import mean

"""# **DEFINICJA FUNKCJI OPTYMALIZACJI**"""

def rastrigin(*X):
    A = 10
    n=len(X)
    f = A*n + sum([(x*x - A * np.cos(2 * math.pi * x)) for x in X])
    return f

def Rastrigin(X):
    A = 10
    n=len(X)
    f = A*n + sum([(x*x - A * np.cos(2 * math.pi * x)) for x in X])
    return f

def Rastrigin_grad(X): 
  grad = []
  for x in X:
    grad.append(2*x+20*math.pi*np.sin(2*math.pi*x))
  return np.array(grad)

def sphere(*X):
    return sum([(x*x) for x in X])

def Sphere(X):
    return sum([(x*x) for x in X])

def Sphere_grad(X):
  grad = []
  for x in X:
    grad.append(2*x)
  return np.array(grad)

def rosenbrock(*X):
   sum=0
   n=len(X)
   for i in range(n-1):
    sum=sum+(100.0*(X[i+1] - X[i]**2.0)**2.0 + ((1 - X[i])**2.0))
   return sum

def Rosenbrock(X):
   sum=0
   n=len(X)
   for i in range(n-1):
    sum=sum+(100.0*(X[i+1] - X[i]**2.0)**2.0 + ((1 - X[i])**2.0))
   return sum

def Rosenbrock_grad(X):  
  grad=[]
  n=len(X)
  n_1=n-1
  for i in range(n-1):
    grad.append(-400*X[i]*(X[i+1]-X[i]**2)+2*X[i]-2)
  grad.append(200*X[n_1]-200*X[n_1-1]**2)
  return np.array(grad)

# def grad_function(m,funkcja):
#     p = grad(funkcja)
#     y1=p(m)
#     k=len(m)
#     y=np.zeros(k)
#     for i in range (k):
#       y[i]=y1[i]
#     return y

"""# **OPTYMALIZATOR**"""

def adam(cur_x, gradient_funkcji, precision, max_iters, rate, beta1, beta2):
  iters = 0 #iteration counter
  previous_step_size =[0.5]
  eps = 1e-8 #small value
  
  m = np.array([0.0 for _ in range(len(cur_x))])
  v = np.array([0.0 for _ in range(len(cur_x))])
  v_corr_sqrt = np.array([0.0 for _ in range(len(cur_x))])

  Tstart = datetime.datetime.now()
  #print ("Start time: = %s:%s:%s" % (Tstart.hour, Tstart.minute, Tstart.second))

  while max(previous_step_size) > precision and iters < max_iters:

    prev_x = cur_x
    m = beta1 * m + (1.0 - beta1) * gradient_funkcji(prev_x)
    v = beta2 * v + (1.0 - beta2) * gradient_funkcji(prev_x)**2

    m_corr = m / (1.0 - beta1 ** (iters+1))
    v_corr = v / (1.0 - beta2 ** (iters+1))
    for i in range(len(v_corr)):
      v_corr_sqrt[i] = math.sqrt(v_corr[i])
    cur_x = prev_x - rate * m_corr / (v_corr_sqrt + eps)

    previous_step_size = abs(cur_x - prev_x)
    iters = iters+1
    #print("Iteration",iters,"\nX value is",cur_x) #Print iterations

  Tstop = datetime.datetime.now()
  #print ("Start time: = %s:%s:%s" % (Tstart.hour, Tstart.minute, Tstart.second))
  #print ("Stop time: = %s:%s:%s" % (Tstop.hour, Tstop.minute, Tstop.second))
  Total_time = (Tstop.hour*3600+Tstop.minute*60+Tstop.second)-(Tstart.hour*3600+Tstart.minute*60+Tstart.second)
  #print ("Total time: = %s seconds" % (Total_time))    
  #print("The local minimum occurs at", cur_x)
  return Total_time, cur_x

# #warunki stop
# precision = 0.00001 
# max_iters = 10000
# #parametry
# rate = 0.01 # Learning rate alpha
# beta1 = 0.9 
# beta2 = 0.99 
# xn = 2
# cur_x = np.random.uniform(0,1,xn)

# precision = 1e-10
# czas_1_total,x_1=adam(cur_x, Rastrigin_grad, precision, max_iters, rate, beta1, beta2)
# print(x_1)

# precision = 1e-10
# czas_2_total,x_2=adam(cur_x, Sphere_grad, precision, max_iters, rate, beta1, beta2)
# print(x_2)

# precision = 1e-5 
# czas_3_total,x_3=adam(cur_x, Rosenbrock_grad, precision, max_iters, rate, beta1, beta2)
# print(x_3)

"""# **PĘTLA GŁÓWNA**"""

#warunki stop 
max_iters = 10000
#parametry
rate = 0.01 # Learning rate
beta1 = 0.9 
beta2 = 0.99 

czas_1_total = [[0]*5 for i in range(11)] #inicjalizacja tablic
czas_2_total = [[0]*5 for i in range(11)]
czas_3_total = [[0]*5 for i in range(11)]
best_1 = [[0] for i in range(11)]
mean_1 = [[0] for i in range(11)]
best_x1 = [[0] for i in range(11)]
best_2 = [[0] for i in range(11)]
mean_2 = [[0] for i in range(11)]
best_x2 = [[0] for i in range(11)]
best_3 = [[0] for i in range(11)]
mean_3 = [[0] for i in range(11)]
best_x3 = [[0] for i in range(11)]

for xi in range(11):
  xn=2**(xi+1) #liczba zmiennych decyzyjnych
  f1_celu = [] #inicjalizacja tablic
  f2_celu = []
  f3_celu = []
  print(xn)
  #print(xi) 
  temp_suma=0

  for i in range(5):
    start_x = np.random.uniform(0,1,xn) #inicjalizacja początkowych wartości zmiennych decyzyjnych
    czas_1 = 0
    czas_2 = 0
    czas_3 = 0

    x_1 = 0
    x_2 = 0
    x_3 = 0

    precision = 1e-6
    czas_1_total[xi][i],x_1=adam(start_x, Rastrigin_grad, precision, max_iters, rate, beta1, beta2)
    czas_2_total[xi][i],x_2=adam(start_x, Sphere_grad, precision, max_iters, rate, beta1, beta2)
    precision = 1e-4 
    czas_3_total[xi][i],x_3=adam(start_x, Rosenbrock_grad, precision, max_iters, rate, beta1, beta2)

    if i<1:
      all_x1 = x_1
      all_x2 = x_2
      all_x3 = x_3
    else:
      all_x1 = np.vstack((all_x1, x_1)) #generowanie wektora wartości
      all_x2 = np.vstack((all_x2, x_2))
      all_x3 = np.vstack((all_x3, x_3))

    f1_celu.append(Rastrigin(x_1)) #generowanie listy wartości funkcji celu
    f2_celu.append(Sphere(x_2))
    f3_celu.append(Rosenbrock(x_3))
  best_1[xi] = min(f1_celu) #najlepsza wartosc funkcji celu
  mean_1[xi] = mean(np.array(f1_celu)) #średnia wartość funckji celu
  best_x1[xi] = all_x1[f1_celu.index(best_1[xi]),:] #zwracanie najlepszych wartości zmiennych decyzyjnych

  best_2[xi] = min(f2_celu)
  mean_2[xi] = mean(np.array(f2_celu))
  best_x2[xi] = all_x2[f2_celu.index(best_2[xi]),:]

  best_3[xi] = min(f3_celu)
  mean_3[xi] = mean(np.array(f3_celu))
  best_x3[xi] = all_x3[f3_celu.index(best_3[xi]),:]

"""# **PREZENTACJA WYNIKÓW**"""

def adam_draw( gradient_funkcji, funkcja, resolution, precision, max_iters, rate, beta1, beta2):

  iters = 0 #iteration counter
  cur_x = np.random.uniform(0,1,2)
  previous_step_size =[0.5]
  eps = 1e-8 #small value
  
  m = np.array([0.0 for _ in range(len(cur_x))])
  v = np.array([0.0 for _ in range(len(cur_x))])
  v_corr_sqrt = np.array([0.0 for _ in range(len(cur_x))])

  X = np.linspace(-2, 2, 200)    
  Y = np.linspace(-2, 2, 200)    

  X, Y = np.meshgrid(X, Y)

  Z = funkcja(X, Y)
  Z = np.array(Z)
  Z = Z.reshape((len(X), len(Y)))

  plt.contour(X,Y,Z, resolution)

  while max(previous_step_size) > precision and iters < max_iters:

    plt.scatter(cur_x[0], cur_x[1])
    prev_x = cur_x
    m = beta1 * m + (1.0 - beta1) * gradient_funkcji(prev_x)
    v = beta2 * v + (1.0 - beta2) * gradient_funkcji(prev_x)**2

    m_corr = m / (1.0 - beta1 ** (iters+1))
    v_corr = v / (1.0 - beta2 ** (iters+1))
    for i in range(len(v_corr)):
      v_corr_sqrt[i] = math.sqrt(v_corr[i])
    cur_x = prev_x - rate * m_corr / (v_corr_sqrt + eps)

    previous_step_size = abs(cur_x - prev_x)
    iters = iters+1

  plt.show()
  print(cur_x)

# np.zeros(11)
srednia_czas_1=[[0] for i in range(11)]
srednia_czas_2=[[0] for i in range(11)]
srednia_czas_3=[[0] for i in range(11)]
for j in range(11):
  temp_suma_1=0
  temp_suma_2=0
  temp_suma_3=0
  for i in range(5):
    temp_suma_1=temp_suma_1+czas_1_total[j][i]
    temp_suma_2=temp_suma_2+czas_2_total[j][i]
    temp_suma_3=temp_suma_3+czas_3_total[j][i]
  srednia_czas_1[j]=temp_suma_1/5
  srednia_czas_2[j]=temp_suma_2/5
  srednia_czas_3[j]=temp_suma_3/5
#print(srednia_czas_1)
#print(srednia_czas_2)
#print(srednia_czas_3)

hist1 = best_x1[10]
hist2 = best_x2[10]
hist3 = best_x3[10]

os_x=[[2**(i+1)] for i in range(11)]
plt.plot(os_x,srednia_czas_1)
plt.ylabel('Czas wykonywania algorytmu')
plt.xlabel('liczba zmiennych')
plt.title('Czas wykonywania algorytmu od\nzmiennych decyzyjnych dla funkcji Rastrigin')
plt.grid()
plt.show()

plt.plot(os_x,srednia_czas_2)
plt.ylabel('Czas wykonywania algorytmu')
plt.xlabel('liczba zmiennych')
plt.title('Czas wykonywania algorytmu od\nzmiennych decyzyjnych dla funkcji Shpere')
plt.grid()
plt.show()

plt.plot(os_x,srednia_czas_3)
plt.ylabel('Czas wykonywania algorytmu')
plt.xlabel('liczba zmiennych')
plt.title('Czas wykonywania algorytmu od\nzmiennych decyzyjnych dla funkcji Rosenbrock')
plt.grid()
plt.show()

plt.plot(os_x,best_1)
plt.ylabel('Wartość funkcji celu')
plt.xlabel('liczba zmiennych')
plt.title('Najlepsza wart. f. celu od liczby\nzm. decyzyjnych (Rastrigin)')
plt.grid()
plt.show()
plt.plot(os_x,best_2)
plt.ylabel('Wartość funkcji celu')
plt.xlabel('liczba zmiennych')
plt.title('Najlepsza wart. f. celu od liczby\nzm. decyzyjnych (Shpere)')
plt.grid()
plt.show()
plt.plot(os_x,best_3)
plt.ylabel('Wartość funkcji celu')
plt.xlabel('liczba zmiennych')
plt.title('Najlepsza wart. f. celu od liczby\nzm. decyzyjnych (Rosenbrock)')
plt.grid()
plt.show()

plt.plot(os_x,mean_1)
plt.ylabel('Wartość funkcji celu')
plt.xlabel('liczba zmiennych')
plt.title('Średnia wart. f. celu od liczby\nzm. decyzyjnych (Rastrigin)')
plt.grid()
plt.show()
plt.plot(os_x,mean_2)
plt.ylabel('Wartość funkcji celu')
plt.xlabel('liczba zmiennych')
plt.title('Średnia wart. f. celu od liczby\nzm. decyzyjnych (Shpere)')
plt.grid()
plt.show()
plt.plot(os_x,mean_3)
plt.ylabel('Wartość funkcji celu')
plt.xlabel('liczba zmiennych')
plt.title('Średnia wart. f. celu od liczby\nzm. decyzyjnych (Rosenbrock)')
plt.grid()
plt.show()

plt.hist(hist1)
plt.ylabel('Liczba zmiennych decyzyjnych')
plt.xlabel('Wartość zmiennej decyzyjnej')
plt.title('Rozkład wart. najlepszych zmiennych\ndec. dla 2048 zmiennych (Rastrigin)')
plt.show()
plt.hist(hist2)
plt.ylabel('Liczba zmiennych decyzyjnych')
plt.xlabel('Wartość zmiennej decyzyjnej')
plt.title('Rozkład wart. najlepszych zmiennych\ndec. dla 2048 zmiennych (Sphere)')
plt.show()
plt.hist(hist3)
plt.ylabel('Liczba zmiennych decyzyjnych')
plt.xlabel('Wartość zmiennej decyzyjnej')
plt.title('Rozkład wart. najlepszych zmiennych\ndec. dla 2048 zmiennych (Rosenbrock)')
plt.show()

rate = 0.01
beta1 = 0.9
beta2 = 0.99
max_iters = 10000

adam_draw(Rastrigin_grad, rastrigin, 10, 1e-10, max_iters, rate, beta1, beta2)
adam_draw(Sphere_grad, sphere, 50, 1e-10, max_iters, rate, beta1, beta2)
adam_draw(Rosenbrock_grad, rosenbrock, 100, 1e-5, max_iters, rate, beta1, beta2)