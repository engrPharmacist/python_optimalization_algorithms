# -*- coding: utf-8 -*-
"""RMS_prop_v1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sDc5ukWT_AmPIFEIGa977tQ6Yko3_1_H

Importowanie bibliotek
"""

import numpy as np
import matplotlib.pyplot as plt
import math
from numpy import arange
from numpy import meshgrid
import sympy as smp
import scipy
from scipy.misc import derivative
import datetime
from statistics import mean

"""Definica funkcji optymalizacji"""

def rastrigin(*X):
    A = 10
    n=len(X)
    f = A*n + sum([(x*x - A * np.cos(2 * math.pi * x)) for x in X])
    return f

def Rastrigin(X):
    A = 10
    n=len(X)
    f = A*n + sum([(x*x - A * np.cos(2 * math.pi * x)) for x in X])
    return f

def Rastrigin_grad(X): 
  grad = []
  for x in X:
    grad.append(2*x+20*math.pi*np.sin(2*math.pi*x))
  return np.array(grad)

def sphere(*X):
    return sum([(x*x) for x in X])

def Sphere(X):
    return sum([(x*x) for x in X])

def Sphere_grad(X):
  grad = []
  for x in X:
    grad.append(2*x)
  return np.array(grad)

def rosenbrock(*X):
   sum=0
   n=len(X)
   for i in range(n-1):
    sum=sum+(100.0*(X[i+1] - X[i]**2.0)**2.0 + ((1 - X[i])**2.0))
   return sum

def Rosenbrock(X):
   sum=0
   n=len(X)
   for i in range(n-1):
    sum=sum+(100.0*(X[i+1] - X[i]**2.0)**2.0 + ((1 - X[i])**2.0))
   return sum

def Rosenbrock_grad(X):  
  grad=[]
  n=len(X)
  n_1=n-1
  for i in range(n-1):
    grad.append(-400*X[i]*(X[i+1]-X[i]**2)+2*X[i]-2)
  grad.append(200*X[n_1]-200*X[n_1-1]**2)
  return np.array(grad)

def grad_function(m,funkcja):
    p = grad(funkcja)
    y1=p(m)
    k=len(m)
    y=np.zeros(k)
    for i in range (k):
      y[i]=y1[i]
    return y

def rms_prop(cur_x, gradient_funkcji, precision, sq_grad_val, max_iters, rate , rho):
  iters = 0 #iteration counter
  previous_step_size =[0.5]
  sq_grad = [0.5]
  eps = 1e-8 #small value

  Tstart = datetime.datetime.now()
  #print ("Start time: = %s:%s:%s" % (Tstart.hour, Tstart.minute, Tstart.second))
  sq_grad_avg = np.array([0.0 for _ in range(len(cur_x))])
  sq_grad_avg_sqrt = np.zeros(len(cur_x))

  while max(sq_grad) > sq_grad_val and max(previous_step_size) > precision and iters < max_iters:
      prev_x = cur_x #Store current x value in prev_x
      sq_grad = gradient_funkcji(prev_x)**2
      sq_grad_avg = (sq_grad_avg * rho) + (1 - rho) * sq_grad
      for i in range(len(sq_grad_avg)):
        sq_grad_avg_sqrt[i] = math.sqrt(sq_grad_avg[i])
      alpha = rate / (sq_grad_avg_sqrt+eps)
      cur_x = cur_x - (alpha * gradient_funkcji(prev_x))
      #alpha = rate / (math.sqrt(sq_grad_avg)+eps)
      #cur_x -= alpha * gradient_funkcji(prev_x)
      previous_step_size = abs(cur_x - prev_x) #Change in x
      iters = iters+1 #iteration count
      #print("Iteration",iters,"\nX value is",cur_x) #Print iterations

  Tstop = datetime.datetime.now()
  #print ("Start time: = %s:%s:%s" % (Tstart.hour, Tstart.minute, Tstart.second))
  #print ("Stop time: = %s:%s:%s" % (Tstop.hour, Tstop.minute, Tstop.second))
  Total_time = (Tstop.hour*3600+Tstop.minute*60+Tstop.second)-(Tstart.hour*3600+Tstart.minute*60+Tstart.second)
  #print ("Total time: = %s seconds" % (Total_time))    
  #print("The local minimum occurs at", cur_x)
  return Total_time, cur_x

# rate = 0.0005 # Learning rate
# max_iters = 10000 
# rho = 0.99
# xn = 1024
# cur_x = np.random.uniform(0,1,xn)

# precision = 0
# sq_grad_val = 0.01
# czas_2_total,x_2=rms_prop(cur_x, Rastrigin_grad, precision, sq_grad_val, max_iters, rate, rho)

# precision = 0
# sq_grad_val = 0.001
# czas_2_total,x_2=rms_prop(cur_x, Sphere_grad, precision, sq_grad_val, max_iters, rate, rho)

# precision = 0.0001 
# sq_grad_val = 0
# czas_2_total,x_2=rms_prop(cur_x, Rosenbrock_grad, precision, sq_grad_val, max_iters, rate, rho)

# rate = 0.0005 # Learning rate
# precision = 0.001 
# max_iters = 10000
# rho = 0.99
# sq_grad = [0.5]
# xn = 2
# eps = 1e-8
# cur_x = np.random.uniform(0,1,2)
# previous_step_size =[0.5]
# iters = 0
# sq_grad_avg = np.array([0.0 for _ in range(len(cur_x))])
# sq_grad_avg_sqrt = np.zeros(len(cur_x))

# while max(sq_grad) > precision and iters < max_iters:
#   prev_x = cur_x
#   print(prev_x,'prev_x start')
#   sq_grad = Rosenbrock_grad(prev_x)**2
#   print(sq_grad,'sq_grad')
#   sq_grad_avg = (sq_grad_avg * rho) + (1 - rho) * sq_grad
#   print(sq_grad_avg,'sq_grad_avg')
#   for i in range(len(sq_grad_avg)):
#     sq_grad_avg_sqrt[i] = math.sqrt(sq_grad_avg[i])
#   print(sq_grad_avg_sqrt,'sq_grad_avg_sqrt')
#   alpha = rate / (sq_grad_avg_sqrt + eps)
#   print(alpha,'alpha')
#   cur_x = cur_x - (alpha * Rosenbrock_grad(prev_x))

#   print(cur_x,'cur_x')
#   print(prev_x,'prev_x stop')
#   previous_step_size = abs(cur_x - prev_x)
#   print(previous_step_size,'previous_step_size')
#   iters = iters+1

#czas_2_total,x_2=rms_prop(cur_x, Sphere_grad, precision, max_iters, rate, rho)

"""# **PĘTLA GŁÓWNA**"""

rate = 0.0005 # Learning rate
max_iters = 5000 
rho = 0.99
czas_1_total = [[0]*5 for i in range(11)] #inicjalizacja tablic
czas_2_total = [[0]*5 for i in range(11)]
czas_3_total = [[0]*5 for i in range(11)]
best_1 = [[0] for i in range(11)]
mean_1 = [[0] for i in range(11)]
best_x1 = [[0] for i in range(11)]
best_2 = [[0] for i in range(11)]
mean_2 = [[0] for i in range(11)]
best_x2 = [[0] for i in range(11)]
best_3 = [[0] for i in range(11)]
mean_3 = [[0] for i in range(11)]
best_x3 = [[0] for i in range(11)]

for xi in range(11):
  xn=2**(xi+1) #liczba zmiennych decyzyjnych
  f1_celu = [] #inicjalizacja tablic
  f2_celu = []
  f3_celu = []
  print(xn)
  #print(xi) 
  temp_suma=0

  for i in range(5):
    start_x = np.random.uniform(0,1,xn) #inicjalizacja początkowych wartości zmiennych decyzyjnych
    czas_1 = 0
    czas_2 = 0
    czas_3 = 0

    x_1 = 0
    x_2 = 0
    x_3 = 0

    czas_1_total[xi][i],x_1=rms_prop(start_x, Rastrigin_grad, 0, 0.02, max_iters, rate, rho)
    czas_2_total[xi][i],x_2=rms_prop(start_x, Sphere_grad, 0, 0.001, max_iters, rate, rho)
    czas_3_total[xi][i],x_3=rms_prop(start_x, Rosenbrock_grad, 0.00009 , 0, max_iters, rate, rho)
    if i<1:
      all_x1 = x_1
      all_x2 = x_2
      all_x3 = x_3
    else:
      all_x1 = np.vstack((all_x1, x_1)) #generowanie wektora wartości
      all_x2 = np.vstack((all_x2, x_2))
      all_x3 = np.vstack((all_x3, x_3))

    f1_celu.append(Rastrigin(x_1)) #generowanie listy wartości funkcji celu
    f2_celu.append(Sphere(x_2))
    f3_celu.append(Rosenbrock(x_3))
  best_1[xi] = min(f1_celu) #najlepsza wartosc funkcji celu
  mean_1[xi] = mean(np.array(f1_celu)) #średnia wartość funckji celu
  best_x1[xi] = all_x1[f1_celu.index(best_1[xi]),:] #zwracanie najlepszych wartości zmiennych decyzyjnych

  best_2[xi] = min(f2_celu)
  mean_2[xi] = mean(np.array(f2_celu))
  best_x2[xi] = all_x2[f2_celu.index(best_2[xi]),:]

  best_3[xi] = min(f3_celu)
  mean_3[xi] = mean(np.array(f3_celu))
  best_x3[xi] = all_x3[f3_celu.index(best_3[xi]),:]

"""# **PREZENTACJA WYNIKÓW**"""

def rms_prop_draw(gradient_funkcji, funkcja, resolution, precision, sq_grad_val, max_iters, rate , rho):

  cur_x = np.random.uniform(0,1,2)
  iters = 0 #iteration counter
  previous_step_size =[0.5]
  sq_grad = [0.5]
  eps = 1e-8 #small value

  sq_grad_avg = np.array([0.0 for _ in range(len(cur_x))])
  sq_grad_avg_sqrt = np.zeros(len(cur_x))

  X = np.linspace(-2, 2, 200)    
  Y = np.linspace(-2, 2, 200)    

  X, Y = np.meshgrid(X, Y)

  Z = funkcja(X, Y)
  Z = np.array(Z)
  Z = Z.reshape((len(X), len(Y)))

  plt.contour(X,Y,Z, resolution)

  while max(sq_grad) > sq_grad_val and max(previous_step_size) > precision and iters < max_iters:
      plt.scatter(cur_x[0], cur_x[1])
      prev_x = cur_x #Store current x value in prev_x
      sq_grad = gradient_funkcji(prev_x)**2
      sq_grad_avg = (sq_grad_avg * rho) + (1 - rho) * sq_grad
      for i in range(len(sq_grad_avg)):
        sq_grad_avg_sqrt[i] = math.sqrt(sq_grad_avg[i])
      alpha = rate / (sq_grad_avg_sqrt+eps)
      cur_x = cur_x - (alpha * gradient_funkcji(prev_x))
      previous_step_size = abs(cur_x - prev_x) #Change in x
      iters = iters+1 #iteration count

  plt.show()
  print(cur_x)

# np.zeros(11)
srednia_czas_1=[[0] for i in range(11)]
srednia_czas_2=[[0] for i in range(11)]
srednia_czas_3=[[0] for i in range(11)]
for j in range(11):
  temp_suma_1=0
  temp_suma_2=0
  temp_suma_3=0
  for i in range(5):
    temp_suma_1=temp_suma_1+czas_1_total[j][i]
    temp_suma_2=temp_suma_2+czas_2_total[j][i]
    temp_suma_3=temp_suma_3+czas_3_total[j][i]
  srednia_czas_1[j]=temp_suma_1/5
  srednia_czas_2[j]=temp_suma_2/5
  srednia_czas_3[j]=temp_suma_3/5
#print(srednia_czas_1)
#print(srednia_czas_2)
#print(srednia_czas_3)

hist1 = best_x1[10]
hist2 = best_x2[10]
hist3 = best_x3[10]

os_x=[[2**(i+1)] for i in range(11)]
plt.plot(os_x,srednia_czas_1)
plt.ylabel('Czas wykonywania algorytmu')
plt.xlabel('liczba zmiennych')
plt.title('Czas wykonywania algorytmu od\nzmiennych decyzyjnych dla funkcji Rastrigin')
plt.grid()
plt.show()

plt.plot(os_x,srednia_czas_2)
plt.ylabel('Czas wykonywania algorytmu')
plt.xlabel('liczba zmiennych')
plt.title('Czas wykonywania algorytmu od\nzmiennych decyzyjnych dla funkcji Shpere')
plt.grid()
plt.show()

plt.plot(os_x,srednia_czas_3)
plt.ylabel('Czas wykonywania algorytmu')
plt.xlabel('liczba zmiennych')
plt.title('Czas wykonywania algorytmu od\nzmiennych decyzyjnych dla funkcji Rosenbrock')
plt.grid()
plt.show()

plt.plot(os_x,best_1)
plt.ylabel('Wartość funkcji celu')
plt.xlabel('liczba zmiennych')
plt.title('Najlepsza wart. f. celu od liczby\nzm. decyzyjnych (Rastrigin)')
plt.grid()
plt.show()
plt.plot(os_x,best_2)
plt.ylabel('Wartość funkcji celu')
plt.xlabel('liczba zmiennych')
plt.title('Najlepsza wart. f. celu od liczby\nzm. decyzyjnych (Shpere)')
plt.grid()
plt.show()
plt.plot(os_x,best_3)
plt.ylabel('Wartość funkcji celu')
plt.xlabel('liczba zmiennych')
plt.title('Najlepsza wart. f. celu od liczby\nzm. decyzyjnych (Rosenbrock)')
plt.grid()
plt.show()

plt.plot(os_x,mean_1)
plt.ylabel('Wartość funkcji celu')
plt.xlabel('liczba zmiennych')
plt.title('Średnia wart. f. celu od liczby\nzm. decyzyjnych (Rastrigin)')
plt.grid()
plt.show()
plt.plot(os_x,mean_2)
plt.ylabel('Wartość funkcji celu')
plt.xlabel('liczba zmiennych')
plt.title('Średnia wart. f. celu od liczby\nzm. decyzyjnych (Shpere)')
plt.grid()
plt.show()
plt.plot(os_x,mean_3)
plt.ylabel('Wartość funkcji celu')
plt.xlabel('liczba zmiennych')
plt.title('Średnia wart. f. celu od liczby\nzm. decyzyjnych (Rosenbrock)')
plt.grid()
plt.show()

plt.hist(hist1)
plt.ylabel('Liczba zmiennych decyzyjnych')
plt.xlabel('Wartość zmiennej decyzyjnej')
plt.title('Rozkład wart. najlepszych zmiennych\ndec. dla 2048 zmiennych (Rastrigin)')
plt.show()
plt.hist(hist2)
plt.ylabel('Liczba zmiennych decyzyjnych')
plt.xlabel('Wartość zmiennej decyzyjnej')
plt.title('Rozkład wart. najlepszych zmiennych\ndec. dla 2048 zmiennych (Sphere)')
plt.show()
plt.hist(hist3)
plt.ylabel('Liczba zmiennych decyzyjnych')
plt.xlabel('Wartość zmiennej decyzyjnej')
plt.title('Rozkład wart. najlepszych zmiennych\ndec. dla 2048 zmiennych (Rosenbrock)')
plt.show()
rate = 0.0005
rho = 0.99
max_iters = 5000
rms_prop_draw(Rastrigin_grad,rastrigin,10 , 0, 0.02, max_iters, rate, rho)
rms_prop_draw(Sphere_grad,sphere,50 , 0, 0.001, max_iters, rate, rho)
rms_prop_draw(Rosenbrock_grad,rosenbrock,100 , 0.00001, 0, max_iters, rate, rho)

def draw(cur_x, funkcja, resolution):
  X = np.linspace(-2, 2, 200)    
  Y = np.linspace(-2, 2, 200)    

  X, Y = np.meshgrid(X, Y)

  Z = funkcja(X, Y)
  Z = np.array(Z)
  Z = Z.reshape((len(X), len(Y)))

  plt.contour(X,Y,Z, resolution)
  plt.scatter(cur_x[0], cur_x[1])
  plt.show()